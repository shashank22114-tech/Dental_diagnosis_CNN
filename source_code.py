# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cxQoLmP5WVjnFkTBvnrpy2HPRez4B9nq
"""

import os, torch
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader, WeightedRandomSampler

# ------------------ UNZIP DATA ------------------
!unzip -q "data.zip" -d /content/

# Try to automatically find dataset root
def find_dataset_root(base="/content"):
    for root, dirs, files in os.walk(base):
        if all(x in dirs for x in ["train", "valid", "test"]):
            return root
    return None

DATASET_ROOT = find_dataset_root("/content")
if DATASET_ROOT is None:
    raise FileNotFoundError("Could not find 'train', 'valid', 'test' folders inside the zip.")
print(f"Found dataset root: {DATASET_ROOT}")

# ------------------ TRANSFORMS ------------------
IMG_SIZE = 384
train_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandAugment(num_ops=3, magnitude=7),
    transforms.ColorJitter(0.3, 0.3, 0.3),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
eval_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

# ------------------ LOAD DATASETS ------------------
train_ds = ImageFolder(os.path.join(DATASET_ROOT, "train"), transform=train_tfms)
valid_ds = ImageFolder(os.path.join(DATASET_ROOT, "valid"), transform=eval_tfms)
test_ds  = ImageFolder(os.path.join(DATASET_ROOT, "test"),  transform=eval_tfms)

print("Original classes:", train_ds.classes)

# ------------------ MAP TO BINARY LABELS ------------------
mapping = {
    "Fillings": 1,          # Periodontitis-related
    "Cavity": 1,
    "Impacted Tooth": 1,
    "Implant": 0,           # Non-root
    "Normal": 0
}

def remap_labels(dataset):
    dataset.samples = [(path, mapping[dataset.classes[label]]) for path, label in dataset.samples]
    dataset.targets = [mapping[dataset.classes[label]] for label in dataset.targets]
    dataset.classes = ["Non-root", "Periodontitis"]
    return dataset

train_ds = remap_labels(train_ds)
valid_ds = remap_labels(valid_ds)
test_ds  = remap_labels(test_ds)

print("Mapped classes:", train_ds.classes)

# ------------------ BALANCED SAMPLER ------------------
counts = torch.bincount(torch.tensor(train_ds.targets))
weights = 1.0 / counts.float()
sample_weights = [weights[label] for label in train_ds.targets]
sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)

# ------------------ DATALOADERS ------------------
train_loader = DataLoader(train_ds, batch_size=8, sampler=sampler, num_workers=2, pin_memory=True)
valid_loader = DataLoader(valid_ds, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=8, shuffle=False, num_workers=2, pin_memory=True)

print(f"\n Dataset ready for training!")
print(f"Train size: {len(train_ds)} | Valid: {len(valid_ds)} | Test: {len(test_ds)}")

# ============================================================
# ResNet50 â€” Optimized Training (AMP, caching, better dataloaders, progressive unfreeze, TTA)
# Target: 90%+ on large dataset (tweakable)
# ============================================================

import os, time, copy, random
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt, seaborn as sns

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import resnet50, ResNet50_Weights

from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve

# -------------------- CONFIG --------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)
if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

# You can reduce IMG_SIZE to speed up (320 gives big speed gains; 384 for better accuracy)
IMG_SIZE = 320        # try 320 (faster) or 384 (slower, slightly more accurate)
BATCH_SIZE = 16       # increase if you have more GPU memory
NUM_EPOCHS_STAGE1 = 6 # head-only
NUM_EPOCHS_STAGE2 = 8 # unfreeze layer4
NUM_EPOCHS_STAGE3 = 8 # fine-tune whole net
MIXUP_PROB = 0.5      # apply mixup with this prob during early epochs
MIXUP_ALPHA = 0.8

SAVE_PATH = "/content/best_resnet50_optimized.pth"

# -------------------- DATASET DETECTION & TRANSFORMS --------------------
def find_dataset_root(base="/content"):
    for root, dirs, files in os.walk(base):
        if all(x in dirs for x in ["train", "valid", "test"]):
            return root
    return None

DATASET_ROOT = find_dataset_root("/content")
if DATASET_ROOT is None:
    raise FileNotFoundError("Could not find train/valid/test under /content. Make sure data.zip was unzipped.")
print("Using dataset root:", DATASET_ROOT)

train_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandAugment(num_ops=2, magnitude=6),
    transforms.ColorJitter(0.2,0.2,0.15),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(12),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

eval_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

# load ImageFolder and remap to binary
train_ds_raw = ImageFolder(os.path.join(DATASET_ROOT, "train"), transform=train_tfms)
valid_ds_raw = ImageFolder(os.path.join(DATASET_ROOT, "valid"), transform=eval_tfms)
test_ds_raw  = ImageFolder(os.path.join(DATASET_ROOT, "test"),  transform=eval_tfms)

print("Original classes (train):", train_ds_raw.classes)

# mapping 5->binary (adjust if you want different mapping)
mapping = {"Fillings":1, "Cavity":1, "Impacted Tooth":1, "Implant":0, "Normal":0}

def remap_imagefolder(imgfolder, mapping):
    # rewrite samples and targets in-place
    new_samples = []
    for p, lbl in imgfolder.samples:
        cls_name = imgfolder.classes[lbl]
        new_lbl = mapping[cls_name]
        new_samples.append((p, new_lbl))
    imgfolder.samples = new_samples
    imgfolder.targets = [lbl for _, lbl in new_samples]
    imgfolder.classes = ["Non-root", "Periodontitis"]
    return imgfolder

train_ds = remap_imagefolder(train_ds_raw, mapping)
valid_ds = remap_imagefolder(valid_ds_raw, mapping)
test_ds  = remap_imagefolder(test_ds_raw, mapping)

print("Mapped classes:", train_ds.classes)
print(f"Train size: {len(train_ds)} | Valid: {len(valid_ds)} | Test: {len(test_ds)}")

# -------------------- Balanced sampler and dataloaders (fast) --------------------
counts = torch.bincount(torch.tensor(train_ds.targets))
print("Class counts (train):", counts.tolist())
weights = 1.0 / counts.float()
sample_weights = [weights[label] for label in train_ds.targets]

# dynamic workers
num_workers = min(8, max(1, (os.cpu_count() or 2) - 1))
print("num_workers:", num_workers)

sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)

# prefer larger batch if GPU memory allows
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,
                          num_workers=num_workers, pin_memory=True, persistent_workers=True)
valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False,
                          num_workers=num_workers, pin_memory=True, persistent_workers=True)
test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,
                          num_workers=num_workers, pin_memory=True, persistent_workers=True)

# -------------------- CUDNN BENCHMARK --------------------
torch.backends.cudnn.benchmark = True

# -------------------- OPTIONAL: Cache Valid/Test (faster eval) --------------------
class CachedDataset(Dataset):
    def __init__(self, ds):
        self.samples = []
        for img, lbl in tqdm(ds, desc="Caching dataset"):
            # ds returns (tensor, label)
            self.samples.append((img, lbl))
    def __len__(self): return len(self.samples)
    def __getitem__(self, idx): return self.samples[idx]

# Cache valid/test into memory (fast). Skip if you run out of RAM.
CACHE_VALID = True
if CACHE_VALID:
    print("Caching validation and test sets into RAM (faster validation)...")
    valid_ds_cached = CachedDataset(valid_ds)
    test_ds_cached  = CachedDataset(test_ds)
    valid_loader = DataLoader(valid_ds_cached, batch_size=BATCH_SIZE, shuffle=False,
                              num_workers=0, pin_memory=True)
    test_loader  = DataLoader(test_ds_cached, batch_size=BATCH_SIZE, shuffle=False,
                              num_workers=0, pin_memory=True)

# -------------------- LOSS (Focal + Label Smoothing) --------------------
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.85, gamma=2.0):
        super().__init__()
        self.alpha, self.gamma = alpha, gamma
    def forward(self, logits, targets):
        # logits: (B,1), targets: (B,1)
        BCE = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')
        pt = torch.exp(-BCE)
        loss = self.alpha * (1 - pt) ** self.gamma * BCE
        return loss.mean()

class SmoothLoss(nn.Module):
    def __init__(self, base_loss, smoothing=0.04):
        super().__init__()
        self.base_loss = base_loss
        self.smoothing = smoothing
    def forward(self, logits, targets):
        targets = targets * (1 - self.smoothing) + 0.5 * self.smoothing
        return self.base_loss(logits, targets)

criterion = SmoothLoss(FocalLoss(alpha=0.85, gamma=2.0), smoothing=0.04)

# -------------------- MIXUP (optional early) --------------------
def mixup_data(x, y, alpha=0.8):
    lam = np.random.beta(alpha, alpha)
    index = torch.randperm(x.size(0)).to(DEVICE)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, preds, y_a, y_b, lam):
    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)

# -------------------- MODEL SETUP (ResNet50) --------------------
model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
# replace head
in_features = model.fc.in_features
model.fc = nn.Sequential(nn.Dropout(0.4), nn.Linear(in_features, 1))
model = model.to(DEVICE)

# optimizer + scheduler (CosineRestarts)
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=8, T_mult=1)

# mixed precision scaler
scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == "cuda"))

# -------------------- UTILS: evaluation + TTA --------------------
def evaluate(model, loader, thr=0.5, tta=False):
    model.eval()
    y_true, y_prob = [], []
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(DEVICE)
            if tta:
                # simple horizontal flip TTA
                imgs_flip = torch.flip(imgs, dims=[3])
                with torch.cuda.amp.autocast(enabled=(DEVICE.type=="cuda")):
                    out1 = torch.sigmoid(model(imgs)).cpu().numpy().flatten()
                    out2 = torch.sigmoid(model(imgs_flip)).cpu().numpy().flatten()
                probs = (out1 + out2) / 2.0
            else:
                with torch.cuda.amp.autocast(enabled=(DEVICE.type=="cuda")):
                    probs = torch.sigmoid(model(imgs)).cpu().numpy().flatten()
            y_true.extend(labels.numpy().tolist())
            y_prob.extend(probs.tolist())
    y_true = np.array(y_true); y_prob = np.array(y_prob)
    y_pred = (y_prob > thr).astype(int)
    acc = accuracy_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_prob)
    return acc, auc, y_true, y_pred, y_prob

# -------------------- TRAINING FUNCTION (one epoch) --------------------
def train_one_epoch(model, loader, optimizer, criterion, scaler, epoch,
                    mixup_prob=MIXUP_PROB, mixup_alpha=MIXUP_ALPHA):
    model.train()
    total_loss = 0.0; total_samples = 0
    correct = 0; total = 0
    pbar = tqdm(loader, desc=f"Train E{epoch}", leave=False)
    for imgs, labels in pbar:
        imgs = imgs.to(DEVICE); labels = labels.to(DEVICE).float().unsqueeze(1)
        optimizer.zero_grad()
        with torch.cuda.amp.autocast(enabled=(DEVICE.type=="cuda")):
            if random.random() < mixup_prob:
                mixed_x, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)
                preds = model(mixed_x)
                loss = mixup_criterion(criterion, preds, y_a, y_b, lam)
            else:
                preds = model(imgs)
                loss = criterion(preds, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        total_loss += loss.item() * imgs.size(0)
        total_samples += imgs.size(0)
        pred_labels = (torch.sigmoid(preds) > 0.5).float()
        correct += (pred_labels == labels).sum().item()
        total += labels.size(0)
        pbar.set_postfix({"loss": total_loss/total_samples, "acc": correct/total})
    return total_loss / total_samples, correct / total

# -------------------- PROGRESSIVE TRAINING --------------------
best_val_acc = 0.0
best_state = None
patience = 0
MAX_PATIENCE = 6

# Stage 0: Freeze backbone except fc (head train)
for name, param in model.named_parameters():
    param.requires_grad = False
for name, param in model.fc.named_parameters():
    param.requires_grad = True
print("Stage0: training head only")

for epoch in range(1, NUM_EPOCHS_STAGE1 + 1):
    t0 = time.time()
    # in early stages use mixup_prob high; we'll reduce later
    loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, scaler, epoch,
                                   mixup_prob=0.7 if epoch <= 3 else 0.5)
    scheduler.step(epoch + epoch/1000.0)
    val_acc, val_auc, _, _, _ = evaluate(model, valid_loader, thr=0.5, tta=False)
    print(f"[Stage0] Epoch {epoch} | train_acc {tr_acc:.4f} | val_acc {val_acc:.4f} | val_auc {val_auc:.3f} | time {time.time()-t0:.1f}s")
    if val_acc > best_val_acc:
        best_val_acc = val_acc; best_state = copy.deepcopy(model.state_dict()); torch.save(best_state, SAVE_PATH); patience = 0
        print("   new best saved")
    else:
        patience += 1
        if patience >= MAX_PATIENCE:
            print("  early stopping stage0")
            break

# Stage 1: Unfreeze layer4 + fc
print("Stage1: unfreezing layer4")
for name, param in model.named_parameters():
    if "layer4" in name or "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False

# reset patience
patience = 0
for epoch in range(1, NUM_EPOCHS_STAGE2 + 1):
    t0 = time.time()
    loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, scaler, epoch+100,
                                   mixup_prob=0.4 if epoch <= 3 else 0.2)
    scheduler.step(epoch + epoch/1000.0)
    val_acc, val_auc, _, _, _ = evaluate(model, valid_loader, thr=0.5, tta=False)
    print(f"[Stage1] Epoch {epoch} | train_acc {tr_acc:.4f} | val_acc {val_acc:.4f} | val_auc {val_auc:.3f} | time {time.time()-t0:.1f}s")
    if val_acc > best_val_acc:
        best_val_acc = val_acc; best_state = copy.deepcopy(model.state_dict()); torch.save(best_state, SAVE_PATH); patience = 0
        print("new best saved")
    else:
        patience += 1
        if patience >= MAX_PATIENCE:
            print("  early stopping stage1")
            break

# Stage 2: Unfreeze all and fine-tune whole network
print("Stage2: unfreezing all layers (full fine-tune)")
for name, param in model.named_parameters():
    param.requires_grad = True

patience = 0
for epoch in range(1, NUM_EPOCHS_STAGE3 + 1):
    t0 = time.time()
    loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, scaler, epoch+200,
                                   mixup_prob=0.0)  # disable mixup in final stage
    scheduler.step(epoch + epoch/1000.0)
    # Use TTA on validation for a robust threshold decision near end
    val_acc, val_auc, y_val, y_val_pred, y_val_prob = evaluate(model, valid_loader, thr=0.5, tta=False)
    print(f"[Stage2] Epoch {epoch} | train_acc {tr_acc:.4f} | val_acc {val_acc:.4f} | val_auc {val_auc:.3f} | time {time.time()-t0:.1f}s")
    if val_acc > best_val_acc:
        best_val_acc = val_acc; best_state = copy.deepcopy(model.state_dict()); torch.save(best_state, SAVE_PATH); patience = 0
        print("  new best saved")
    else:
        patience += 1
        if patience >= MAX_PATIENCE:
            print("  early stopping stage2")
            break

print("Training finished. Best validation accuracy:", best_val_acc)

# -------------------- LOAD BEST, EVALUATE ON TEST (with TTA) --------------------
model.load_state_dict(torch.load(SAVE_PATH, map_location=DEVICE))
model.eval()
# choose best threshold based on validation probs if available; otherwise default 0.5
try:
    # if y_val_prob exists from last evaluation
    from sklearn.metrics import precision_recall_curve
    thr_candidates = np.linspace(0.3, 0.7, 41)
    best_thr = 0.5
    if 'y_val_prob' in locals():
        best_thr = thr_candidates[np.argmax([accuracy_score(y_val, (y_val_prob>t).astype(int)) for t in thr_candidates])]
    print("Using threshold:", best_thr)
except Exception:
    best_thr = 0.5

test_acc, test_auc, y_true, y_pred_raw, y_prob = evaluate(model, test_loader, thr=best_thr, tta=True)
print(f"\nFINAL Test Accuracy: {test_acc*100:.2f}% | AUC: {test_auc:.3f}")

print("\nClassification Report:")
print(classification_report(y_true, y_pred_raw, target_names=["Non-root", "Periodontitis"], digits=4))

cm = confusion_matrix(y_true, y_pred_raw)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non-root", "Periodontitis"], yticklabels=["Non-root", "Periodontitis"])
plt.xlabel("Predicted"); plt.ylabel("Actual"); plt.title("Confusion Matrix"); plt.show()

# ROC curve
fpr, tpr, _ = roc_curve(y_true, y_prob)
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"ROC (AUC={test_auc:.3f})", linewidth=2)
plt.plot([0,1],[0,1],"--", color="gray")
plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
plt.title("ROC Curve - ResNet50")
plt.legend(); plt.grid(True); plt.show()

print("Saved best model to:", SAVE_PATH)

# ==========================
#  ROC & AUC Visualization
# ==========================
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np

# Ensure y_true and y_prob exist (from evaluate() or test evaluation)
fpr, tpr, thresholds = roc_curve(y_true, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(7,6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC curve (AUC = {roc_auc:.3f})")
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - ResNet50')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Optional: display threshold points
for i, thr in enumerate(np.linspace(0.1, 0.9, 9)):
    idx = np.argmin(np.abs(thresholds - thr))
    print(f"Threshold {thr:.2f} => (FPR={fpr[idx]:.3f}, TPR={tpr[idx]:.3f})")

# ==========================
# Grad-CAM Visualization
# ==========================
import torch
from torchvision import transforms
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt

# Load the best model weights
model.load_state_dict(torch.load("/content/best_resnet50_optimized.pth", map_location=DEVICE))
model.eval()

# --- GradCAM Helper ---
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output.detach()

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0].detach()

    def generate(self, input_image, target_class=None):
        self.model.zero_grad()
        output = self.model(input_image)
        if target_class is None:
            target_class = (output > 0).float()
        output.backward(torch.ones_like(output))
        grads = self.gradients
        activations = self.activations
        weights = grads.mean(dim=(2, 3), keepdim=True)
        cam = (weights * activations).sum(dim=1, keepdim=True)
        cam = torch.relu(cam)
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        return cam

# --- Prepare GradCAM ---
target_layer = model.layer4[-1]  # last ResNet block
gradcam = GradCAM(model, target_layer)

# Pick any image from test set
import random
img_path, label = random.choice(test_ds_raw.samples)
img = Image.open(img_path).convert("RGB")

transform = transforms.Compose([
    transforms.Resize((320, 320)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])
input_tensor = transform(img).unsqueeze(0).to(DEVICE)

# Forward pass
cam_map = gradcam.generate(input_tensor)
cam_map = cam_map.squeeze().cpu().numpy()
cam_map = cv2.resize(cam_map, (320, 320))
cam_map = (cam_map - cam_map.min()) / (cam_map.max() + 1e-8)

# Overlay heatmap
img_np = np.array(img.resize((320,320)))
heatmap = cv2.applyColorMap(np.uint8(255 * cam_map), cv2.COLORMAP_JET)
overlay = cv2.addWeighted(heatmap, 0.4, img_np, 0.6, 0)

plt.figure(figsize=(10,5))
plt.subplot(1,3,1); plt.imshow(img_np); plt.title(f"Original ({['Non-root','Periodontitis'][label]})"); plt.axis('off')
plt.subplot(1,3,2); plt.imshow(cam_map, cmap='jet'); plt.title("Grad-CAM Map"); plt.axis('off')
plt.subplot(1,3,3); plt.imshow(overlay); plt.title("Overlayed Heatmap"); plt.axis('off')
plt.tight_layout(); plt.show()

from google.colab import files

files.download('/content/best_resnet50_optimized.pth')